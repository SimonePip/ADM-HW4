{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b1fd8974-2acd-4254-9886-e07c5bce32cd",
   "metadata": {},
   "source": [
    "# Part 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9e07a89-49af-442f-bfc3-66641af36957",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 1.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2216bfe8-15e6-4644-9fa8-9ca25bf4cdd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#part1\n",
    "import numpy as np      \n",
    "import matplotlib.pyplot as plt \n",
    "import scipy.io.wavfile \n",
    "import subprocess\n",
    "import librosa\n",
    "import librosa.display\n",
    "import IPython.display as ipd\n",
    "\n",
    "from pathlib import Path, PurePath   \n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import random\n",
    "import pandas as pd\n",
    "import sympy\n",
    "import difflib\n",
    "from scipy.spatial import distance\n",
    "import os\n",
    "\n",
    "#part3\n",
    "from random import randint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bdb0088-63ea-4646-a9d6-47111989b5cc",
   "metadata": {},
   "source": [
    "### Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "891a3802-b428-4007-9b5e-6a50deef2f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_mp3_to_wav(audio:str) -> str:  \n",
    "    \"\"\"Convert an input MP3 audio track into a WAV file.\n",
    "\n",
    "    Args:\n",
    "        audio (str): An input audio track.\n",
    "\n",
    "    Returns:\n",
    "        [str]: WAV filename.\n",
    "    \"\"\"\n",
    "    if audio[-3:] == \"mp3\":\n",
    "        wav_audio = audio[:-3] + \"wav\"\n",
    "        if not Path(wav_audio).exists():\n",
    "                subprocess.check_output(f\"ffmpeg -i {audio} {wav_audio}\", shell=True)\n",
    "        return wav_audio\n",
    "    \n",
    "    return audio\n",
    "\n",
    "def plot_spectrogram_and_picks(track:np.ndarray, sr:int, peaks:np.ndarray, onset_env:np.ndarray) -> None:\n",
    "    \"\"\"[summary]\n",
    "\n",
    "    Args:\n",
    "        track (np.ndarray): A track.\n",
    "        sr (int): Aampling rate.\n",
    "        peaks (np.ndarray): Indices of peaks in the track.\n",
    "        onset_env (np.ndarray): Vector containing the onset strength envelope.\n",
    "    \"\"\"\n",
    "    times = librosa.frames_to_time(np.arange(len(onset_env)),\n",
    "                            sr=sr, hop_length=HOP_SIZE)\n",
    "\n",
    "    plt.figure()\n",
    "    ax = plt.subplot(2, 1, 2)\n",
    "    D = librosa.stft(track)\n",
    "    librosa.display.specshow(librosa.amplitude_to_db(np.abs(D), ref=np.max),\n",
    "                            y_axis='log', x_axis='time')\n",
    "    plt.subplot(2, 1, 1, sharex=ax)\n",
    "    plt.plot(times, onset_env, alpha=0.8, label='Onset strength')\n",
    "    plt.vlines(times[peaks], 0,\n",
    "            onset_env.max(), color='r', alpha=0.8,\n",
    "            label='Selected peaks')\n",
    "    plt.legend(frameon=True, framealpha=0.8)\n",
    "    plt.axis('tight')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def load_audio_picks(audio, duration, hop_size):\n",
    "    \"\"\"[summary]\n",
    "\n",
    "    Args:\n",
    "        audio (string, int, pathlib.Path or file-like object): [description]\n",
    "        duration (int): [description]\n",
    "        hop_size (int): \n",
    "\n",
    "    Returns:\n",
    "        tuple: Returns the audio time series (track) and sampling rate (sr), a vector containing the onset strength envelope\n",
    "        (onset_env), and the indices of peaks in track (peaks).\n",
    "    \"\"\"\n",
    "    try:\n",
    "        track, sr = librosa.load(audio, duration=duration)\n",
    "        onset_env = librosa.onset.onset_strength(track, sr=sr, hop_length=hop_size)\n",
    "        peaks = librosa.util.peak_pick(onset_env, 10, 10, 10, 10, 0.5, 0.5)\n",
    "    except Error as e:\n",
    "        print('An error occurred processing ', str(audio))\n",
    "        print(e)\n",
    "\n",
    "    return track, sr, onset_env, peaks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89ca9f7c-036d-468f-8326-b5a6753b902b",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "79f4626c-948a-48af-8f56-3fdc4f3357bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_TRACKS = 1413\n",
    "HOP_SIZE = 512\n",
    "DURATION = 60\n",
    "THRESHOLD = 0 # TODO: to be tuned!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3f2dfafc-32da-4dea-bdf4-51069cf16230",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = Path(\"Part1/archive/mp3s-32k/\")\n",
    "mp3_tracks = data_folder.glob(\"*/*/*.mp3\")\n",
    "tracks = data_folder.glob(\"*/*/*.wav\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a80a04ea-06a4-4c09-83d9-787b46d60c72",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "06637ebd-38a8-49cf-8ad6-1513878ac8b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fdd3d793e6ce4c239cbc1c8704940442",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1413 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for track in tqdm(mp3_tracks, total=N_TRACKS):\n",
    "    convert_mp3_to_wav(str(track))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56ba8f9d-98f0-46ed-934c-49e64f3cac55",
   "metadata": {},
   "source": [
    "### Store peaks values and tracks titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "79375fbe-fa5c-4694-a23a-3a1d46441f21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbebbb1701914f0c800894103f38c517",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "all_peaks=[]\n",
    "titles=[]\n",
    "t=open('titles.txt','w')\n",
    "p=open('peaks60.txt','w')\n",
    "for ind,audio in tqdm(enumerate(tracks)):\n",
    "    track, sr, onset_env, peaks = load_audio_picks(audio, DURATION, HOP_SIZE)\n",
    "    all_peaks.append(peaks)\n",
    "    title=str(audio).replace('Part1/archive/mp3s-32k/','').replace('.wav','')\n",
    "    #print(title)\n",
    "    titles.append(title)\n",
    "    t.write(title+'\\n')\n",
    "    p.write(str(peaks)+'\\n')\n",
    "t.close()\n",
    "p.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1a89740-0983-4dc2-a449-1ca78675554e",
   "metadata": {},
   "source": [
    "## 1.2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38c1031b-2961-4f00-958c-44ce27b5b3d7",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Create our Database"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ba7f626-145c-4767-ac81-afba6d228f87",
   "metadata": {},
   "source": [
    "Create a dictionary with all the possible peaks as keys and values set to 0, we will use it to map the peaks previously stored into a space that is $\\mathbb{R}^{k}$, with $k=\\#\\,total\\, peaks$. Each of these vectors will be composed by only 0's and 1's, each value representing if the peak appears for that song (0=False, 1=True)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4f3ee3d0-f2b0-49e8-a354-03ca8fd17be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dic={}\n",
    "for peaks in all_peaks:\n",
    "    for peak in peaks:\n",
    "        if peak not in dic:\n",
    "            dic[peak]=0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dcb7dc6-c2e9-4bdd-afc3-1783b67f3dd0",
   "metadata": {},
   "source": [
    "The following function maps each of the peaks array (representing the peaks of a single song) into the space $\\mathbb{R}^{k}$ and returns the 0-1 vector as a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "111059fe-c76a-4971-9faf-f4aefdb51b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform01(array,dic):\n",
    "    \n",
    "    dic=dict.fromkeys(dic, 0) #initialize to 0 all values, we wil call this func multiple tiems and don't want\n",
    "                              #mistakes in storing the \n",
    "    \n",
    "    for i in range(len(array)):\n",
    "        dic[array[i]]=1\n",
    "    \n",
    "\n",
    "    return (list(dic.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0a70c232-a4e2-4ecd-995d-fd590a6a6696",
   "metadata": {},
   "outputs": [],
   "source": [
    "peaks_01=[]\n",
    "for i in range(len(all_peaks)):\n",
    "    peaks_01.append(transform01(all_peaks[i],dic))  #peaks_01 now contains all the 01 vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "43d23024-a2bd-4f82-a697-060bdcefb660",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1413 2579\n"
     ]
    }
   ],
   "source": [
    "print(len(peaks_01),len(peaks_01[0])) #---> k=2579"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbe069f0-f394-4ab8-928a-0c8933e96648",
   "metadata": {},
   "source": [
    "As next step we want to reduce the dimensionality of these 0-1 vectors because they are very sparse, to do so we first define a scaling factor $scale$ (we are using $scale=3$) and then compress the vector by that factor as it follows:\\\n",
    "Imagine we have a vecotr $v=[1,0,1,0,0,0,1,1,1]$, we want it to become something like $v'=[1,0,1]$. To achieve this we defined a function that takes as input the scale factor and the vector, which is divided in subvectors each long $scale$. For each of those subvectors we return only 1 item that is the max of the elements in the subvector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "24978f02-7fc1-4517-a722-0062743bec5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "scale=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "62a95086-18a7-4141-9dd0-221c46e446ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaler(array,scale):\n",
    "    scaled_01=[]\n",
    "    for i in range(0,len(array),scale):\n",
    "        summ=max(array[i:i+scale])\n",
    "        scaled_01.append(summ)\n",
    "    return np.asarray(scaled_01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6be369e2-1c51-45c8-9e62-9526af9e63d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(peaks_01)):\n",
    "    peaks_01[i]=scaler(peaks_01[i],scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3b975544-50c3-4d83-9526-fb07ed4adb2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1413 1290\n"
     ]
    }
   ],
   "source": [
    "print(len(peaks_01),len(peaks_01[0])) #---> k=1290"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0473a6b-69e6-481f-b3f2-ccf07c6c689c",
   "metadata": {},
   "source": [
    "Now that a 0-1 vector for each song has been obtained, it will be used to produce a signature as follows:\\\n",
    "Repeat for $n_{permutation}=300$ times:\n",
    "\n",
    "1.   Perform a random shuffling over the elements of the 0-1 vector;\n",
    "1.   Store the index of the first \"1\" element into the signature for the song;\n",
    "\n",
    "By doing this we are further reducing the dimensions of each vector from $\\mathbb{R}^{k=1290}$ to $\\mathbb{R}^{n_{permutation}=300}$, this will allow for faster operations on the vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9c81cb3c-6eb4-4cfb-8106-90022e5bfed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_perms=300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9d28d9dc-a67b-4bda-815a-955bdbc61b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def first1(array): #returns the index of the first '1' element of a np.array\n",
    "    return np.where(array==1)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fedcd40a-17f5-4f83-a1bf-1fb6419cb12d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def minHash(array,n_perms): #return list with indexes of first element of the given array\n",
    "    \n",
    "    indexes=[]\n",
    "    random.seed(42) #set seed so we are applying the same transformation to the vectors when iterating(see later)\n",
    "    \n",
    "    for i in range(n_perms):\n",
    "        random.shuffle(array)\n",
    "        indexes.append(first1(array))\n",
    "    return indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "81e22ef6-2745-443c-9c5d-48cac4d10624",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b0318056ce745c4b2bc8dd5003dbe8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1413 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#now save in an array the values we get applying minHash on the whole list of vectors\n",
    "new_indexes=[]\n",
    "for i in tqdm(range(len(peaks_01))): #new_indexes will have as elements the columns of the signature matrix \n",
    "    indexes=minHash(peaks_01[i], n_perms) #we are trying to reduce the dimensions by a factor ~4, \n",
    "    new_indexes.append(np.asarray(indexes))    #that's why 300 perms \n",
    "    #new indexes is list of np.array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "98254ec5-ed3d-4478-b0cf-118ae3b46efc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300 1413\n"
     ]
    }
   ],
   "source": [
    "print(len(new_indexes[0]),len(new_indexes)) #we have 1413 vectors long 300 each, seems fine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96b999da-486a-42e8-be3f-fb905bd12894",
   "metadata": {},
   "source": [
    "So now we have the list 'new_indexes' that contains the columns of the signature matrix, which is a matrix (300,1413) ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f7d3a6c-186b-43b2-ad3c-1ff4b8a28592",
   "metadata": {},
   "source": [
    "### Create Buckets for faster matching with queries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83766aba-c7f5-46f4-ad73-306e700470da",
   "metadata": {},
   "source": [
    "In this section we are dividing the signature matrix in bands, each band containing $bandwidth=4$ rows. Then we map each of the bands through a hash function into a value $v\\,\\epsilon\\,(0,mod)$. The mod value used for the hash function is computed as follows:\n",
    "* We first compute $m=k^{bandwidth}$, then we start increasing $m$ by 1 until when it is a prime number, when the condition is satisfied we assign $mod=m$. As such we choose $m$ to be the first prime number greater than $k *bandwidth$: we want to be able to represent at least $k*bandwidth$ combinations ($=\\#(combinations\\,each\\,band\\,can\\, assume)$).\n",
    "\n",
    "After this we store the data obtained in a dictionary as follows $data[v]=index$ where index refers to the index of the song, which we will use to retrieve the songs' titles later on when trying to match queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ae067b95-c74d-493c-a7f7-5943c972bc4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "bandwidth=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cb4685a0-85b6-4a5d-af1e-269c0e49aa60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def findMod(l_01,bandwidth):\n",
    "    m=l_01**bandwidth\n",
    "    while(True):\n",
    "        m+=1\n",
    "        if(sympy.isprime(m)):\n",
    "            break\n",
    "    print(\"Module value chosen for the hash is: \",m)\n",
    "    return(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2ba9abcc-c34c-4276-8712-0f32e4bbd0da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Module value chosen for the hash is:  2769228810013\n"
     ]
    }
   ],
   "source": [
    "mod=findMod(len(peaks_01[0]),bandwidth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "94ce32c0-493a-4928-9e3c-6ef965169f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "#if I want to do with hash function.... choose prime number =1423\n",
    "def rands(n,prime):\n",
    "    a=[]\n",
    "    random.seed(42)\n",
    "    for i in range(n):\n",
    "        a.append(random.randint(0, prime-1))\n",
    "    return a\n",
    "\n",
    "def hashf(A,a,prime,mod):\n",
    "    a=np.asarray(a)\n",
    "    A=np.asarray(A)\n",
    "    return (np.sum(a*A))%prime\n",
    "\n",
    "def mapHash(A,bandwidth,mod):\n",
    "    prime=1423\n",
    "    a=rands(bandwidth,prime)\n",
    "    return hashf(A,a,prime,mod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bf64aefa-9c3c-47a1-a422-6b951098d206",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Bucket1(array, data, bandwidth,mod):\n",
    "    \n",
    "    for j in tqdm(range(len(array))):\n",
    "        \n",
    "        for i in range(0,len(array[j]),bandwidth):\n",
    "            \n",
    "            key=mapHash(array[j][i:i+bandwidth],bandwidth,mod)\n",
    "            \n",
    "            if key not in data:\n",
    "                data[key]=[]\n",
    "                data[key].append(int(j))\n",
    "            else:\n",
    "                data[key].append(int(j))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "25b607b2-5010-4359-9418-40ae05ffd84d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e78a6d1faed42749ee04197a2ed0c74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1413 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data={}\n",
    "data=dict.fromkeys(data, 0)\n",
    "data=Bucket1(new_indexes,data,bandwidth,mod)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a197e6fd-0b5a-4486-b4c3-0ca434f2d9bd",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Prepare to compare queries with dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a16cee28-f272-4222-8f70-bead582cf751",
   "metadata": {},
   "outputs": [],
   "source": [
    "def globsort(s):\n",
    "    return int(os.path.basename(s)[5:-4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0ebdaefe-aa2d-4e75-b1d7-007f6fa82552",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_folder = Path(\"Part1/queries/\")\n",
    "q_tracks = sorted(query_folder.glob(\"*.wav\"),key=globsort)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a998157-3a8d-455b-bcb0-24cb05f77bb9",
   "metadata": {},
   "source": [
    "Define a similarity score to compare the query with the elements in our dataset and a function to retrieve the title of a song given its index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1663a920-854b-42ff-80e0-617ff0ddf832",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def sim_score(a1,a2): #returns value in interval (0,1) that states how similar two arrays are\n",
    "    #return difflib.SequenceMatcher(None,a1,a2).ratio()\n",
    "    return sum(a1==a2)/len(a1)\n",
    "    \n",
    "def retrieveTitle(index): #Return the title of a song given its index\n",
    "    f=open('titles.txt')\n",
    "    lines=f.readlines()\n",
    "    f.close()\n",
    "    return lines[index]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b482c348-3975-4d14-a32a-23445f83ee39",
   "metadata": {
    "tags": []
   },
   "source": [
    "For each of the query songs we do the following:\n",
    "1. Get the values of its peaks\n",
    "1. Transform them into a 01 vector and scale by $scale$ factor\n",
    "1. Apply minHash to retrieve a vector we called $sign\\_colq$\n",
    "1. Map to buckets\n",
    "1. Compare the vector $sign\\_colq$ with the possible vectors saved in the buckets (actually their index $index\\,song$ is saved, we compare with $new_indexes$)\n",
    "1. Pick the song with highest similarity value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "421e3796-6b30-4bd1-beff-0091a591b790",
   "metadata": {},
   "source": [
    "### Analyze varying threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91e03d38-5443-4384-9a67-047841883292",
   "metadata": {},
   "source": [
    "We introduce a threshold parameter for the queries, in case we want to look for similar songs to those of the query: when threshold < 1: songs in dataset that are similar to the query are reported for each track; when threshold $\\equiv $1: songs in dataset that exactly match the query are reported for each track."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "250cdd02-c43f-4bba-bc3e-4c18ede1ad96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for threshold value=0.3\n",
      "Requested song of track1 should be steely_dan/Countdown_To_Ecstasy/03-The_Boston_Rag\n",
      "\n",
      "Requested song of track2 should be green_day/Warning/12-Macy_s_Day_Parade\n",
      "\n",
      "Requested song of track3 should be prince/Parade/06-Life_Can_be_so_Nice\n",
      "\n",
      "Requested song of track4 should be steely_dan/Katy_Lied/02-Bad_Sneakers\n",
      "\n",
      "Requested song of track5 should be tori_amos/The_Beekeeper/12-Original_Sinsuality\n",
      "\n",
      "Requested song of track6 should be prince/Parade/03-I_Wonder_U\n",
      "\n",
      "Requested song of track7 should be radiohead/Pablo_Honey/04-Stop_Whispering\n",
      "\n",
      "Requested song of track8 should be depeche_mode/Black_Celebration/02-Fly_on_the_windscreen\n",
      "\n",
      "Requested song of track9 should be cure/The_Top/07-Piggy_In_The_Mirror\n",
      "\n",
      "Requested song of track10 should be tori_amos/To_Venus_and_Back-Orbiting/09-Datura\n",
      "\n",
      "\n",
      "\n",
      "for threshold value=0.8\n",
      "Requested song of track1 should be steely_dan/Countdown_To_Ecstasy/03-The_Boston_Rag\n",
      "\n",
      "Requested song of track2 should be green_day/Warning/12-Macy_s_Day_Parade\n",
      "\n",
      "Requested song of track3 should be prince/Parade/06-Life_Can_be_so_Nice\n",
      "\n",
      "Requested song of track4 should be steely_dan/Katy_Lied/02-Bad_Sneakers\n",
      "\n",
      "Requested song of track5 should be tori_amos/The_Beekeeper/12-Original_Sinsuality\n",
      "\n",
      "Requested song of track6 should be prince/Parade/03-I_Wonder_U\n",
      "\n",
      "Requested song of track7 should be radiohead/Pablo_Honey/04-Stop_Whispering\n",
      "\n",
      "Requested song of track8 should be depeche_mode/Black_Celebration/02-Fly_on_the_windscreen\n",
      "\n",
      "Requested song of track9 should be cure/The_Top/07-Piggy_In_The_Mirror\n",
      "\n",
      "Requested song of track10 should be tori_amos/To_Venus_and_Back-Orbiting/09-Datura\n",
      "\n",
      "\n",
      "\n",
      "for threshold value=1.0\n",
      "Requested song of track1 should be aerosmith/Aerosmith/03-Dream_On\n",
      "\n",
      "Requested song of track2 should be queen/The_Works/06-I_Want_To_Break_Free\n",
      "\n",
      "Requested song of track3 should be u2/October/07-October\n",
      "\n",
      "Requested song of track4 should be beatles/The_White_Album_Disc_1/04-Ob-La-Di_Ob-La-Da\n",
      "\n",
      "Requested song of track5 should be radiohead/OK_Computer/06-Karma_Police\n",
      "\n",
      "Requested song of track6 should be led_zeppelin/Led_Zeppelin_II/05-Heartbreaker\n",
      "\n",
      "Requested song of track7 should be fleetwood_mac/Rumours/05-Go_Your_Own_Way\n",
      "\n",
      "Requested song of track8 should be green_day/American_Idiot/01-American_Idiot\n",
      "\n",
      "Requested song of track9 should be depeche_mode/Some_Great_Reward/06-Somebody\n",
      "\n",
      "Requested song of track10 should be steely_dan/Katy_Lied/01-Black_Friday\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "THRESHOLD=[0.3,0.8,1.]\n",
    "\n",
    "for thresh in THRESHOLD:\n",
    "    print('for threshold value={}'.format(thresh))\n",
    "    for q_track in q_tracks:\n",
    "        track, sr, onset_env, peakis = load_audio_picks(q_track, DURATION, HOP_SIZE)  \n",
    "        q_01=np.array([0])\n",
    "        q_01=peakis\n",
    "        q_01=transform01(q_01,dic)                \n",
    "        q_01=scaler(q_01,scale)\n",
    "        sign_colq=minHash(q_01,n_perms)                                           \n",
    "        \n",
    "        keys=[]\n",
    "        for i in range(0,len(sign_colq),bandwidth):                                   \n",
    "            key=mapHash(sign_colq[i:i+bandwidth],bandwidth,mod)                              \n",
    "            keys.append(key)  \n",
    "            \n",
    "        score=-1\n",
    "        for key in keys:\n",
    "            for value in data[key]:                                                   \n",
    "                similarity=sim_score(sign_colq,new_indexes[value])\n",
    "                if (similarity>score) & (similarity<=thresh):\n",
    "                    best=value\n",
    "                    score=similarity\n",
    "        if score!=-1:                                                                  \n",
    "            print(('Requested song of {} should be {}').format(str(q_track).replace('Part1/queries/','').replace('.wav','')\n",
    "                                                                     ,retrieveTitle(best)))\n",
    "        else:\n",
    "            print(('threshold is too low, no match for {} in the buckets').format(str(q_track).replace('Part1/queries/','').replace('.wav','')))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1544a09-715e-40dd-8546-bec4750e0f16",
   "metadata": {},
   "source": [
    "# Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44a13ffe-1e38-4e6a-b87a-883e35b1d097",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c97303fb-576a-4af7-bf9f-28ef9d69052b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a854cf47-02e7-45a0-88f6-07f8c532a1bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ac7834a-2311-4c03-8a47-389d7c9f333e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "840310b5-8bf2-433d-94c6-cc0e63e8825d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0394098-2fa0-4143-9789-970d53d1a009",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4254def3-1b21-46fa-8ff2-40e94f08efc2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80034560-6884-417e-850b-932d2f11de59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d711510a-36c7-4b19-a9c0-616a3870cb56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae263e82-190e-4722-96b6-cb26204ad6c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ec1b98c-f4f7-48a0-8fa4-91c81886c4d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ddce34-20f0-416f-86e8-42abf0713d4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fe5084a9-6ded-47c3-9fd5-98d5228698bb",
   "metadata": {},
   "source": [
    "# Part 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e84eec52-e52b-4595-9517-a38294f27d93",
   "metadata": {},
   "source": [
    "You are given a list of integers, A, and another integer s. Write an algorithm that outputs all the pairs in A that equal s.\n",
    "For example, if\n",
    "A = [7, -2, 8, 2, 6, 4, -7, 2, 1, 3, -3] and s = 4\n",
    "the algorithm should output: (7, -3), (-2, 6), (2, 2), (3, 1)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2c709d2-e45a-4295-b89a-c279dddc992f",
   "metadata": {},
   "source": [
    "The easy way to solve the problem would be implementing a brute force method, which would lead to a complexity equal to $O(n^2)$.\\\n",
    "We managed to implement an algorithm that, making use of sort method of a list ($O(n\\, log(n)$) and a cycle in which we use two indexes (more details in the code, below) solves the problem in $O(n\\, log(n))$ [removing constants]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a52328a-74e4-431b-9609-5d87f8250f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def findPairs(A,s):\n",
    "    pairs=[]\n",
    "    A.sort                                   #First sort the array O(nlogn)\n",
    "    start=0                                  #We define 2 indexes to go through the list A, and verify wheter the sum\n",
    "    end=len(A)-1                             #of A[index1=start]+A[index2=end] is equal to the given sum, in the case it\n",
    "                                             #is we store the value and keep looking for other values\n",
    "                                             #if it's not we check if that's greater or not of the given sum:\n",
    "    while start<end:                         #in the case it is we decrease the second index (end) while in the other\n",
    "                                             #case we increase the first index (start)\n",
    "        if A[start]+A[end]==s: \n",
    "            pairs.append((A[start],A[end]))\n",
    "            start+=1\n",
    "    \n",
    "        elif A[start]+A[end]<s:\n",
    "            start+=1\n",
    "            \n",
    "        else:\n",
    "            end-=1\n",
    "            \n",
    "    return pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1676c321-c228-4b78-ba3b-e272ef03ce3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "N=10\n",
    "for i in range(5):\n",
    "    A=[]\n",
    "    if i!=0: N*=10\n",
    "    for i in range(N):\n",
    "        A.append(randint(-50, 50))\n",
    "    print(N)\n",
    "    %timeit pairs=findPairs(A,10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
