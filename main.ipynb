{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b1fd8974-2acd-4254-9886-e07c5bce32cd",
   "metadata": {},
   "source": [
    "# Part 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9e07a89-49af-442f-bfc3-66641af36957",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 1.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2216bfe8-15e6-4644-9fa8-9ca25bf4cdd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#part1\n",
    "import numpy as np      \n",
    "import matplotlib.pyplot as plt \n",
    "import scipy.io.wavfile \n",
    "import subprocess\n",
    "import librosa\n",
    "import librosa.display\n",
    "import IPython.display as ipd\n",
    "\n",
    "from pathlib import Path, PurePath   \n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import random\n",
    "import pandas as pd\n",
    "import os\n",
    "import difflib\n",
    "from scipy.spatial import distance\n",
    "\n",
    "\n",
    "#part3\n",
    "from random import randint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bdb0088-63ea-4646-a9d6-47111989b5cc",
   "metadata": {},
   "source": [
    "### Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "891a3802-b428-4007-9b5e-6a50deef2f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_mp3_to_wav(audio:str) -> str:  \n",
    "    \"\"\"Convert an input MP3 audio track into a WAV file.\n",
    "\n",
    "    Args:\n",
    "        audio (str): An input audio track.\n",
    "\n",
    "    Returns:\n",
    "        [str]: WAV filename.\n",
    "    \"\"\"\n",
    "    if audio[-3:] == \"mp3\":\n",
    "        wav_audio = audio[:-3] + \"wav\"\n",
    "        if not Path(wav_audio).exists():\n",
    "                subprocess.check_output(f\"ffmpeg -i {audio} {wav_audio}\", shell=True)\n",
    "        return wav_audio\n",
    "    \n",
    "    return audio\n",
    "\n",
    "def plot_spectrogram_and_picks(track:np.ndarray, sr:int, peaks:np.ndarray, onset_env:np.ndarray) -> None:\n",
    "    \"\"\"[summary]\n",
    "\n",
    "    Args:\n",
    "        track (np.ndarray): A track.\n",
    "        sr (int): Aampling rate.\n",
    "        peaks (np.ndarray): Indices of peaks in the track.\n",
    "        onset_env (np.ndarray): Vector containing the onset strength envelope.\n",
    "    \"\"\"\n",
    "    times = librosa.frames_to_time(np.arange(len(onset_env)),\n",
    "                            sr=sr, hop_length=HOP_SIZE)\n",
    "\n",
    "    plt.figure()\n",
    "    ax = plt.subplot(2, 1, 2)\n",
    "    D = librosa.stft(track)\n",
    "    librosa.display.specshow(librosa.amplitude_to_db(np.abs(D), ref=np.max),\n",
    "                            y_axis='log', x_axis='time')\n",
    "    plt.subplot(2, 1, 1, sharex=ax)\n",
    "    plt.plot(times, onset_env, alpha=0.8, label='Onset strength')\n",
    "    plt.vlines(times[peaks], 0,\n",
    "            onset_env.max(), color='r', alpha=0.8,\n",
    "            label='Selected peaks')\n",
    "    plt.legend(frameon=True, framealpha=0.8)\n",
    "    plt.axis('tight')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def load_audio_picks(audio, duration, hop_size):\n",
    "    \"\"\"[summary]\n",
    "\n",
    "    Args:\n",
    "        audio (string, int, pathlib.Path or file-like object): [description]\n",
    "        duration (int): [description]\n",
    "        hop_size (int): \n",
    "\n",
    "    Returns:\n",
    "        tuple: Returns the audio time series (track) and sampling rate (sr), a vector containing the onset strength envelope\n",
    "        (onset_env), and the indices of peaks in track (peaks).\n",
    "    \"\"\"\n",
    "    try:\n",
    "        track, sr = librosa.load(audio, duration=duration)\n",
    "        onset_env = librosa.onset.onset_strength(track, sr=sr, hop_length=hop_size)\n",
    "        peaks = librosa.util.peak_pick(onset_env, 10, 10, 10, 10, 0.5, 0.5)\n",
    "    except Error as e:\n",
    "        print('An error occurred processing ', str(audio))\n",
    "        print(e)\n",
    "\n",
    "    return track, sr, onset_env, peaks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89ca9f7c-036d-468f-8326-b5a6753b902b",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "79f4626c-948a-48af-8f56-3fdc4f3357bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_TRACKS = 1413\n",
    "HOP_SIZE = 512\n",
    "DURATION = 30 \n",
    "THRESHOLD = 0 # TODO: to be tuned!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3f2dfafc-32da-4dea-bdf4-51069cf16230",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = Path(\"Part1/archive/mp3s-32k/\")\n",
    "mp3_tracks = data_folder.glob(\"*/*/*.mp3\")\n",
    "tracks = data_folder.glob(\"*/*/*.wav\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a80a04ea-06a4-4c09-83d9-787b46d60c72",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "06637ebd-38a8-49cf-8ad6-1513878ac8b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1466b1df44da478d93b2a75c7279db3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1413 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for track in tqdm(mp3_tracks, total=N_TRACKS):\n",
    "    convert_mp3_to_wav(str(track))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56ba8f9d-98f0-46ed-934c-49e64f3cac55",
   "metadata": {},
   "source": [
    "### Store peaks values and tracks titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "79375fbe-fa5c-4694-a23a-3a1d46441f21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e96d00c6c54b4e768459d67387adaf28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "all_peaks=[]\n",
    "titles=[]\n",
    "t=open('titles.txt','w')\n",
    "for ind,audio in tqdm(enumerate(tracks)):\n",
    "    track, sr, onset_env, peaks = load_audio_picks(audio, DURATION, HOP_SIZE)\n",
    "    all_peaks.append(peaks)\n",
    "    title=str(audio).replace('Part1/archive/mp3s-32k/','').replace('.wav','')\n",
    "    #print(title)\n",
    "    titles.append(title)\n",
    "    t.write(title+'\\n')\n",
    "t.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1a89740-0983-4dc2-a449-1ca78675554e",
   "metadata": {},
   "source": [
    "## 1.2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38c1031b-2961-4f00-958c-44ce27b5b3d7",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Create our Database"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ba7f626-145c-4767-ac81-afba6d228f87",
   "metadata": {},
   "source": [
    "Create a dictionary with all the possible peaks as keys and values set to 0, we will use it to map the peaks previously stored into a space that is $\\mathbb{R}^{k}$, with $k=\\#\\,total\\, peaks$. Each of these vectors will be composed by only 0's and 1's, each value representing if the peak appears for that song (0=False, 1=True)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4f3ee3d0-f2b0-49e8-a354-03ca8fd17be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dic={}\n",
    "for peaks in all_peaks:\n",
    "    for peak in peaks:\n",
    "        if peak not in dic:\n",
    "            dic[peak]=0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dcb7dc6-c2e9-4bdd-afc3-1783b67f3dd0",
   "metadata": {},
   "source": [
    "The following function maps each of the peaks array (representing the peaks of a single song) into the space $\\mathbb{R}^{k}$ and returns the vector as a numpy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "111059fe-c76a-4971-9faf-f4aefdb51b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform01(array,dic):\n",
    "    \n",
    "    dic=dict.fromkeys(dic, 0) #initialize to 0 all values, we wil call this func multiple tiems and don't want\n",
    "                              #mistakes in storing the \n",
    "    \n",
    "    for i in range(len(array)):\n",
    "        dic[array[i]]=1\n",
    "        \n",
    "    return np.asarray(list(dic.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0a70c232-a4e2-4ecd-995d-fd590a6a6696",
   "metadata": {},
   "outputs": [],
   "source": [
    "peaks_01=[]\n",
    "for i in range(len(all_peaks)):\n",
    "    peaks_01.append(transform01(all_peaks[i],dic))  #peaks_01 now contains all the 01 vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "43d23024-a2bd-4f82-a697-060bdcefb660",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1413 1287\n"
     ]
    }
   ],
   "source": [
    "print(len(peaks_01),len(peaks_01[0])) #---> k=1287"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0473a6b-69e6-481f-b3f2-ccf07c6c689c",
   "metadata": {},
   "source": [
    "Now that a 01 vector for each song has been obtained, it will be used to produce a signature as follows:\\\n",
    "Repeat for $n_{permutation}=300$ times:\n",
    "\n",
    "1.   Perform a random shuffling over the elements of the 01 vector;\n",
    "1.   Store the index of the first \"1\" element into the signature for the song;\n",
    "\n",
    "By doing this we are reducing the dimensions of each vector from $\\mathbb{R}^{k=1287}$ to $\\mathbb{R}^{n_{permutation}=300}$, this will allow for faster operations on the vectors  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9d28d9dc-a67b-4bda-815a-955bdbc61b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def first1(array): #returns the index of the first '1' element of a np.array\n",
    "    return np.where(array==1)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fedcd40a-17f5-4f83-a1bf-1fb6419cb12d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def minHash(array,n_perms=300): #return list with indexes of first element of the given array\n",
    "    \n",
    "    indexes=[]\n",
    "    random.seed(42) #set seed so we are applying the same transformation to the vectors when iterating(see later)\n",
    "    \n",
    "    for i in range(n_perms):\n",
    "        random.shuffle(array)\n",
    "        indexes.append(first1(array))\n",
    "    return indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "81e22ef6-2745-443c-9c5d-48cac4d10624",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0ffdf791279444082b3aa8ac9b9864c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1413 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#now save in an array the values we get applying minHash on the whole list of vectors\n",
    "new_indexes=[]\n",
    "for i in tqdm(range(len(peaks_01))): #new_indexes will have as elements the columns of the signature matrix \n",
    "    indexes=minHash(peaks_01[i], n_perms=300) #we are trying to reduce the dimensions by a factor ~4, \n",
    "    new_indexes.append(np.asarray(indexes))    #that's why 300 perms \n",
    "    #new indexes is list of np.array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "98254ec5-ed3d-4478-b0cf-118ae3b46efc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300 1413\n"
     ]
    }
   ],
   "source": [
    "print(len(new_indexes[0]),len(new_indexes)) #we have 1413 vectors long 300 each, seems fine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96b999da-486a-42e8-be3f-fb905bd12894",
   "metadata": {},
   "source": [
    "So now we have the list 'new_indexes' that contains the columns of the signature matrix, which is a matrix (300,1413) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f7d3a6c-186b-43b2-ad3c-1ff4b8a28592",
   "metadata": {},
   "source": [
    "### Create Buckets for faster matching with queries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83766aba-c7f5-46f4-ad73-306e700470da",
   "metadata": {},
   "source": [
    "In this section we are dividing the signature matrix in bands, each band containing $bandwidth=10$ rows. Then we map each of the bands through a hash function into a value $v\\,\\epsilon\\,(0,1423)$. After this we store the data obtained in a dictionary as follows $data[v]=index$ where index refers to the index of the song, which we will use to retrieve the songs' titles later on when trying to match queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "94ce32c0-493a-4928-9e3c-6ef965169f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "#if I want to do with hash function.... choose prime number =1423\n",
    "def rands(n,prime):\n",
    "    a=[]\n",
    "    random.seed(42)\n",
    "    for i in range(n):\n",
    "        a.append(random.randint(0, prime-1))\n",
    "    return a\n",
    "\n",
    "def hashf(A,a,prime):\n",
    "    a=np.asarray(a)\n",
    "    A=np.asarray(A)\n",
    "    return (np.sum(a*A))%prime\n",
    "\n",
    "def mapHash(A,bandwidth=10):\n",
    "    prime=1423\n",
    "    a=rands(bandwidth,prime)\n",
    "    return hashf(A,a,prime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bf64aefa-9c3c-47a1-a422-6b951098d206",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Bucket1(array, data, bandwidth=10):\n",
    "    \n",
    "    for j in tqdm(range(len(array))):\n",
    "        \n",
    "        for i in range(0,len(array[j]),bandwidth):\n",
    "            \n",
    "            key=mapHash(array[j][i:i+bandwidth],bandwidth)\n",
    "            \n",
    "            if key not in data:\n",
    "                data[key]=[]\n",
    "                data[key].append(int(j))\n",
    "            else:\n",
    "                data[key].append(int(j))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "25b607b2-5010-4359-9418-40ae05ffd84d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "271be7c9113c448ba5754896f22d82a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1413 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data={}\n",
    "data=dict.fromkeys(data, 0)\n",
    "data=Bucket1(new_indexes,data,bandwidth=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a197e6fd-0b5a-4486-b4c3-0ca434f2d9bd",
   "metadata": {},
   "source": [
    "### Prepare to compare queries with dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a998157-3a8d-455b-bcb0-24cb05f77bb9",
   "metadata": {},
   "source": [
    "Define a similarity score to compare the query with the elements in our dataset and a function to retrieve the title of a song given its index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1663a920-854b-42ff-80e0-617ff0ddf832",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def sim_score(a1,a2): #returns value in interval (0,1) that states how similar two arrays are\n",
    "    return difflib.SequenceMatcher(None,a1,a2).ratio()\n",
    "\n",
    "    \n",
    "def retrieveTitle(index): #Return the title of a song given its index\n",
    "    f=open('titles.txt')\n",
    "    lines=f.readlines()\n",
    "    f.close()\n",
    "    return lines[index]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b482c348-3975-4d14-a32a-23445f83ee39",
   "metadata": {},
   "source": [
    "For each of the query songs we do the following:\n",
    "1. Get the values of its peaks\n",
    "1. Transform them into a 01 vector\n",
    "1. Apply minHash to retrieve a vector we called $sign\\_colq$\n",
    "1. Map to buckets\n",
    "1. Compare the vector $sign\\_colq$ with the possible vectors saved in the buckets (actually their index $index\\,song$ is saved)\n",
    "1. Pick the song with highest similarity value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "69b28038-1b58-4a89-afbe-2dd23aa95d66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requested song of track track1 should be aerosmith/Aerosmith/03-Dream_On\n",
      "\n",
      "Requested song of track track2 should be queen/The_Works/06-I_Want_To_Break_Free\n",
      "\n",
      "Requested song of track track3 should be u2/October/07-October\n",
      "\n",
      "Requested song of track track4 should be beatles/The_White_Album_Disc_1/04-Ob-La-Di_Ob-La-Da\n",
      "\n",
      "Requested song of track track5 should be radiohead/OK_Computer/06-Karma_Police\n",
      "\n",
      "Requested song of track track6 should be led_zeppelin/Led_Zeppelin_II/05-Heartbreaker\n",
      "\n",
      "Requested song of track track7 should be fleetwood_mac/Rumours/05-Go_Your_Own_Way\n",
      "\n",
      "Requested song of track track8 should be green_day/American_Idiot/01-American_Idiot\n",
      "\n",
      "Requested song of track track9 should be depeche_mode/Some_Great_Reward/06-Somebody\n",
      "\n",
      "Requested song of track track10 should be steely_dan/Katy_Lied/01-Black_Friday\n",
      "\n"
     ]
    }
   ],
   "source": [
    "q_tracks=['Part1/queries/track1.wav','Part1/queries/track2.wav','Part1/queries/track3.wav','Part1/queries/track4.wav',\n",
    "          'Part1/queries/track5.wav','Part1/queries/track6.wav','Part1/queries/track7.wav','Part1/queries/track8.wav',\n",
    "          'Part1/queries/track9.wav','Part1/queries/track10.wav']\n",
    "for q_track in q_tracks:\n",
    "    track, sr, onset_env, peakis = load_audio_picks(q_track, DURATION, HOP_SIZE) #point 1\n",
    "    q_01=np.array([0])\n",
    "    q_01=peakis\n",
    "    q_01=transform01(q_01,dic)                                                   #point 2\n",
    "    sign_colq=minHash(q_01,n_perms=300)                                          #point 3\n",
    "    \n",
    "    keys=[]\n",
    "    bandwidth=10\n",
    "    for i in range(0,len(sign_colq),bandwidth):                                  #point 4\n",
    "        key=mapHash(sign_colq[i:i+bandwidth])                              \n",
    "        keys.append(key)  \n",
    "        \n",
    "    score=-1\n",
    "    for key in keys:\n",
    "        for value in data[key]:                                                  #point 5\n",
    "            similarity=sim_score(np.asarray(sign_colq),new_indexes[value])\n",
    "            if similarity>score:\n",
    "                best=value\n",
    "                score=similarity\n",
    "    if best!=-1:                                                                 #point 6\n",
    "        print(('Requested song of track {} should be {}').format(q_track.replace('Part1/queries/','').replace('.wav','')\n",
    "                                                                 ,retrieveTitle(best)))\n",
    "    else:\n",
    "        print('something went wrong...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "250cdd02-c43f-4bba-bc3e-4c18ede1ad96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44a13ffe-1e38-4e6a-b87a-883e35b1d097",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c97303fb-576a-4af7-bf9f-28ef9d69052b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a854cf47-02e7-45a0-88f6-07f8c532a1bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ac7834a-2311-4c03-8a47-389d7c9f333e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "840310b5-8bf2-433d-94c6-cc0e63e8825d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0394098-2fa0-4143-9789-970d53d1a009",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4254def3-1b21-46fa-8ff2-40e94f08efc2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80034560-6884-417e-850b-932d2f11de59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d711510a-36c7-4b19-a9c0-616a3870cb56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae263e82-190e-4722-96b6-cb26204ad6c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ec1b98c-f4f7-48a0-8fa4-91c81886c4d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ddce34-20f0-416f-86e8-42abf0713d4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fe5084a9-6ded-47c3-9fd5-98d5228698bb",
   "metadata": {},
   "source": [
    "# Part 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e84eec52-e52b-4595-9517-a38294f27d93",
   "metadata": {},
   "source": [
    "You are given a list of integers, A, and another integer s. Write an algorithm that outputs all the pairs in A that equal s.\n",
    "For example, if\n",
    "A = [7, -2, 8, 2, 6, 4, -7, 2, 1, 3, -3] and s = 4\n",
    "the algorithm should output: (7, -3), (-2, 6), (2, 2), (3, 1)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2c709d2-e45a-4295-b89a-c279dddc992f",
   "metadata": {},
   "source": [
    "The easy way to solve the problem would be implementing a brute force method, which would lead to a complexity equal to $O(n^2)$.\\\n",
    "We managed to implement an algorithm that, making use of sort method of a list ($O(n\\, log(n)$) and a cycle in which we use two indexes (more details in the code, below) solves the problem in $O(n\\, log(n))$ [removing constants]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7a52328a-74e4-431b-9609-5d87f8250f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def findPairs(A,s):\n",
    "    pairs=[]\n",
    "    A.sort                                   #First sort the array O(nlogn)\n",
    "    start=0                                  #We define 2 indexes to go through the list A, and verify wheter the sum\n",
    "    end=len(A)-1                             #of A[index1=start]+A[index2=end] is equal to the given sum, in the case it\n",
    "                                             #is we store the value and keep looking for other values\n",
    "                                             #if it's not we check if that's greater or not of the given sum:\n",
    "    while start<end:                         #in the case it is we decrease the second index (end) while in the other\n",
    "                                             #case we increase the first index (start)\n",
    "        if A[start]+A[end]==s: \n",
    "            pairs.append((A[start],A[end]))\n",
    "            start+=1\n",
    "    \n",
    "        elif A[start]+A[end]<s:\n",
    "            start+=1\n",
    "            \n",
    "        else:\n",
    "            end-=1\n",
    "            \n",
    "    return pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1676c321-c228-4b78-ba3b-e272ef03ce3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "1.28 µs ± 21 ns per loop (mean ± std. dev. of 7 runs, 1000000 loops each)\n",
      "100\n",
      "12.5 µs ± 436 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)\n",
      "1000\n",
      "137 µs ± 2.13 µs per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n",
      "10000\n",
      "1.43 ms ± 56.5 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n",
      "100000\n",
      "13.7 ms ± 81.8 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "N=10\n",
    "for i in range(5):\n",
    "    A=[]\n",
    "    if i!=0: N*=10\n",
    "    for i in range(N):\n",
    "        A.append(randint(-50, 50))\n",
    "    print(N)\n",
    "    %timeit pairs=findPairs(A,10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
